\documentclass[11pt,a4paper]{book}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{stackrel}
\usepackage{hyperref}
\usepackage{comment} 
\usepackage{xcolor}
\usepackage[left=2.5cm,right=2.5cm,top=2cm,bottom=2.8cm]{geometry}
\setlength{\parskip}{4mm}

\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

\usepackage{wrapfig}
\usepackage{bm}
\usepackage{url}

\PassOptionsToPackage{hyphens}{url} %Permite que los enlaces URL puedan dividirse en múltiples líneas 

\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{esvect}
\usepackage{booktabs} % Para líneas horizontales de aspecto profesional
\usepackage{array} % Para personalizar el ancho de las columnas


%\usepackage{subfig}

\usepackage{float}
\usepackage{enumitem}

\usepackage{natbib}

\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[nottoc]{tocbibind}

\usepackage{synttree} 

\graphicspath{ {images/} }
\let\olditemize\itemize
\def\itemize{\olditemize\itemsep=0pt }
\setlength{\parindent}{0cm}
\setlist[itemize]{topsep=0pt}
\setlist[enumerate]{topsep=0pt}

\newtheorem{teo}{Teorema}[section]
\newtheorem{cor}[teo]{Corolario}
\newtheorem{defi}[teo]{Definición}
\newtheorem{prop}[teo]{Proposición}
\newtheorem{lema}[teo]{Lema}
\newtheorem{conj}[teo]{Conjetura}
\newtheorem{obs}[teo]{Observación}
\newtheorem{ejem}[teo]{Ejemplo}
\newtheorem{axioma}[teo]{Axioma}



\newcommand\Item[1][]{%
  \ifx\mathbb{R}lax#1\mathbb{R}lax  \item \else \item[#1] \fi
  \abovedisplayskip=-4pt\abovedisplayshortskip=0pt~\vspace*{-\baselineskip}}

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert} %Define un nuevo comando \abs para facilitar la escritura de valores absolutos. Cuando uses \abs{x}, esto se representará como |x| con el tamaño de los delimitadores automáticamente ajustado al tamaño de x.

\newcommand{\mbb}{\mathbb}
\newcommand{\lp}{\ensuremath{\left(}}
\newcommand{\rp}{\ensuremath{\right)}}

\usepackage{footmisc}  
\newcounter{samefootnote}
\newcommand{\samesfootnote}{%
    \stepcounter{footnote}%
    \footnotemark[\value{footnote}]%
}

%\usepackage{acronym}

\usepackage{multicol}
\usepackage{longtable}

\usepackage{listings}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\definecolor{lightgrey}{rgb}{0.95,0.95,0.95}

\renewcommand*{\lstlistingname}{Programa}

\lstset{
   language=Python,
   basicstyle=\ttfamily\small,
   keywordstyle=\color{deepblue}\bfseries\itshape,
   commentstyle=\color{deepgreen}\itshape,
   stringstyle=\color{deepred},
   backgroundcolor=\color{lightgrey},
   morekeywords={as,assert,nonlocal,with,yield},
   showstringspaces=false,
   numbers=left,
   rulecolor=\color{black},
   captionpos=b,
   frame=leftline,
   literate=
   {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
   {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
   {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
   {À}{{\`A}}1 {È}{{\`E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
   {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
   {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
   {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
   {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
   {ã}{{\~a}}1 {ẽ}{{\~e}}1 {ĩ}{{\~i}}1 {õ}{{\~o}}1 {ũ}{{\~u}}1
   {Ã}{{\~A}}1 {Ẽ}{{\~E}}1 {Ĩ}{{\~I}}1 {Õ}{{\~O}}1 {Ũ}{{\~U}}1
   {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
   {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1
   {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {Ø}{{\O}}1 {å}{{\r a}}1 {Å}{{\r A}}1
   {€}{{\euro}}1 {£}{{\pounds}}1 {«}{{\guillemotleft}}1
   {»}{{\guillemotright}}1 {ñ}{{\~n}}1 {Ñ}{{\~N}}1 {¿}{{?`}}1 {¡}{{!`}}1 
}


\usepackage{caption}
\usepackage{subcaption}
\usepackage[acronym]{glossaries}

%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\fancyhf{} % Limpia la cabecera y pie de página actuales
%\fancyhead[LO,RE]{\nouppercase{\leftmark}} % Cabecera de la página par (izquierda) e impar (derecha)
%\fancyhead[RO,LE]{\thepage} % Número de página en la cabecera derecha (páginas impares) y izquierda (páginas pares)
%\renewcommand{\headrulewidth}{0pt}
%\renewcommand{\chaptermark}[1]{%
%  \markboth{\chaptername\ \thechapter.\ #1}{}%
%}








\makeatletter
\newcommand{\dotminus}{\mathbin{\text{\@dotminus}}}

\newcommand{\@dotminus}{%
  \ooalign{\hidewidth\raise1ex\hbox{.}\hidewidth\cr$\m@th-$\cr}%
}
\makeatother


\usepackage{mdframed}
\newmdenv[leftline=false,topline=false]{topbot}
            
\author{Pablo Jiménez Poyatos}
\title{TFG}
\date{Julio 2024}


\newacronym{cnn}{CNN}{Convolutional Neural Network}
\newacronym{dnn}{DNN}{Deep Neural Network}
\newacronym{dbns}{DBNs}{Deep Belief Networks}
\newacronym{rnn}{RNN}{Recurrent Neural Network}
\newacronym{rbm}{RBM}{Restricted Boltzmann Machine}



\makeglossaries




\begin{document}
\raggedbottom 
\pagenumbering{gobble}


\begin{titlepage}
		\centering
		
		{ \Large UNIVERSIDAD COMPLUTENSE DE MADRID}
		
		{ \Large \textbf{FACULTAD DE CIENCIAS MATEMÁTICAS}}
		\vspace{0.8cm}
		
		{ \large DEPARTAMENTO DE CIENCIAS DE LA  COMPUTACIÓN}
		\vspace{1cm}
		
		\vspace{0.6cm}
		
		\graphicspath{ {images/} }
		%%%%Logo Complutense%%%%%
		\includegraphics[width=0.35\textwidth]{img/ucm.png} 
		\vspace{0.4cm}
		
        {\Large \textbf{TRABAJO DE FIN DE GRADO}}
		
		\vspace{8mm}
        {\huge \bfseries Algoritmos de Aprendizaje Automático aplicados a problemas de Ciberseguridad\par}
		\vspace{1cm}

		{\large Presentado por: Pablo Jiménez Poyatos}
		
		{\large Dirigido por: Luis Fernando Llana Diaz}
		
		\vspace{1.5cm}
		{\large Grado en Matemáticas}
		
		{\large Curso académico 2023-24}
\end{titlepage}

\thispagestyle{empty}
\clearpage
\setcounter{page}{1}


\newpage
\begin{center}
   {\bf Agradecimientos} 
\end{center}




 

\thispagestyle{empty}
\clearpage
\setcounter{page}{1}


\newpage
\begin{center}
   {\bf Resumen} 
\end{center}
   

\vspace{0.6 cm}
\textsl{\textbf{Palabras clave:} } 



\begin{center}
   {\bf Abstract} 
\end{center}



\vspace{0.6 cm}
\textsl{\textbf{Keywords:} } 


\newpage
\tableofcontents

\newpage
\clearpage
\pagenumbering{arabic}

\input{capitulo01}

\input{capitulo02}

\input{capitulo03}

\input{capitulo04}

\input{capitulo05}


\begin{comment}

\section{Cita bibliografias}

%%Comentar estas notas para que no salgan en la memoria
{\Large\textbf{Nota: el título extendido (si procede), el resumen y el abstract deben estar en una misma página y su extensión no debe superar una página. Tamaño mínimo 11pto.}}
\vspace{1cm}

{\Large\textbf{Extensión máxima 20 páginas sin contar portada ni resumen (sí se incluye índice, introducción, conclusiones y bibliografía}}
\newpage

%%Inicio:
\citep{olabe1998redes} : ESPAÑOL : Muy completo, me gusta
\citep{parisi2019hands} : INGLES información práctica sobre cómo utilizar sistemas de inteligencia artificial para prevenir ataques cibernéticos, detectar amenazas y anomalías en las redes, y fortalecer la seguridad en el ámbito de la ciberseguridad

\subsection{Microsoft}

10800 archivos de prueba de tipo .bytes (otros 10800 de tipo .asm) pero solo usaremos los .bytes. Convertimos cada archivo en una imagen. Primero, cada código hexadecimal lo convertimos a numeros decimales y estos los pasamos a un array de numpy. Hacemos reshape (lado,lado2) de forma que obtengamos la mayor dimension posible que sea casi cuadrado consiguiendo perder la menor información posible. Este reshape lo pasamos a np.uint8 y finalmente lo interpolamos usando bilinal, cubic, bicubic, nearest y observamos cual es la mejor de todas {zhao2023new} (hacer una grafica o algo para comprobarlo). Además, para caragr los datos he usado multiprocessing con los diferentes datos de tiempo. En el caso de algunas imagenes, los archivos .bytes no contienen ningun tipo de informacion(?? ?? ?? ..) todos los byte son ??. Estos ficheros, no estan incluidos en las imagenes ni de entrenamiento ni validación porque no contienen ningun tpo de información. 

Mi modelo es una CNN secuencial. Tengo que generalizarlo por si quiero insertar la layer de 1000 o las de dropout y con que valor(param de entrada). AL igual que el tipo de intepolación. Tener en cuenta que he visto overfitting porque loss y val-loss tienen mucha diferencia por eso aplico dropout.



archivos con todo '??':
da3XhOZzQEbKVtLgMYWv.bytes
a9oIzfw03ED4lTBCt52Y.bytes
fRLS3aKkijp4GH0Ds6Pv.bytes
cf4nzsoCmudt1kwleOTI.bytes
58kxhXouHzFd4g3rmInB.bytes
6tfw0xSL2FNHOCJBdlaA.bytes
IidxQvXrlBkWPZAfcqKT.bytes
d0iHC6ANYGon7myPFzBe.bytes

\citep{narayanan2016performance} : habla sobre los caracteres '??'



\subsection{Páginas web}


\citep{kaggle_cnn_tutorial} : Un tutorial sobre una CNN en python

\citep{conceptos_RN_DesdeCero} : Primera red neuronal que solo hace forwardpropagation


\subsection{Redes neuronales}
\citep{matich2001redes} ESPAÑOL 

\citep{stamp2022artificial} : INLES habla de redes neuronales y ciberseguridad

\citep{tang2007neural} : INGLES redes neuronales



\citep{mirjalili2020python} : Tiene una lectura muy facil y conceptos bastante bien expresados y explicados. Es un libro muy práctico con bastantes ejemplos en python usando Scikit-learn y TensorFlow.



cuando usamos reshape, dimensiones tienen que coincidir. Sale en https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
\citep{ni2018malware} : De donde sale que usamos interpolacion para cargar las imagenes

\citep{zhao2023new} : De donde sale que usamos interpolacion para cargar las imagenes

\citep{hinton2012improving} : porque dropout in full connected layers

\citep{zhao2023new} : diferentes tipos de interpolacion

\citep{he2019malware}: interpolation bilineal

\citep{gibert2019using} : resultados de microsoft big data

\citep{ni2018malware} : resultados Microsoft data

\citep{sharma2024migan} : Microsoft malware

\citep{kornish2018malware} : crear las imagenes de microsoft

\citep{luo2017binary} : conversion malware to image 

\citep{simonyan2014very} : random cropped for large datset


\citep{habibi2023performance} : dicen que adam, adammax y tal son mejores optimizadores

\subsection{Ciberseguridad}

MCFT-CNN: Malware classification with fine-tune convolution neural
networks using traditional and transfer learning in Internet of Things IMPORTANTE EN LA PAGINA 5 HAY IMAGEN DONDE PONE RESIZE AND RESHAPE

\cite{yagual2022revision} : ESPAÑOL, Analiza cuatro técnicas populares de redes neuronales y de aprendizaje profundo, en el contexto de la ciberseguridad : perceptrón multicapa (MLP), las redes neuronales convolucionales (CNN), las redes neuronales recurrentes (RNN) y el aprendizaje profundo por transferencia (DTL). Estas técnicas y sus modelos de seguridad híbridos pueden utilizarse para abordar de forma inteligente diferentes problemas de ciberdelitos, como la detección de intrusiones, el análisis de malware, el análisis de amenazas de seguridad, la predicción de ciberataques o anomalías, etc. 
\begin{enumerate}
\item Algoritmos NN
\item Que algoritmo de cada NN se aplica a cada problema de ciberseguridad. Nada explicativo.
\end{enumerate}

\citep{omar2022machine} : INGLES pero es libro que tiene muy buena pinta 50 pags

\citep{sarker2020cybersecurity} INGLES

\citep{xin2018machine} INGLES : La introducción destaca la creciente integración de Internet en la vida social y cómo esto está cambiando la forma en que las personas aprenden y trabajan, pero también expone a amenazas de seguridad cada vez más graves. El artículo se centra en la importancia de identificar diversos ataques informáticos, en particular, los no vistos previamente. Se menciona que la ciberseguridad es un conjunto de tecnologías y procesos diseñados para proteger computadoras, redes, programas y datos de ataques y accesos no autorizados.

Se explica que los sistemas de seguridad de red constan de un sistema de seguridad de red y un sistema de seguridad informática, y que cada uno de estos sistemas incluye cortafuegos, software antivirus y sistemas de detección de intrusiones. Se detalla que los sistemas de detección de intrusiones (IDS) ayudan a identificar comportamientos no autorizados en el sistema.

Se mencionan tres tipos principales de análisis de redes para los IDS: basado en el uso (conocido como basado en firmas), basado en anomalías y híbrido. Se destaca que las técnicas basadas en anomalías son atractivas porque pueden detectar ataques no conocidos y se adaptan a actividades normales personalizadas para cada sistema, lo que dificulta a los atacantes saber qué actividades pueden realizar sin ser detectados.

El artículo describe que las técnicas híbridas combinan la detección de uso y la detección de anomalías y se utilizan para aumentar la detección de intrusiones conocidas y reducir las tasas de falsos positivos de ataques desconocidos. Se menciona que la mayoría de los métodos de aprendizaje automático (ML) y aprendizaje profundo (DL) son híbridos.

Luego, se presenta una revisión de la literatura sobre métodos de ML y DL para aplicaciones de ciberseguridad, con un enfoque en tecnologías de seguridad de red y sus descripciones. El artículo se centra en proporcionar información detallada sobre los métodos de ML y DL, así como referencias a trabajos fundamentales en cada método.

Se señala que el artículo no describe todas las técnicas de detección de anomalías de red, sino que se concentra en los métodos de ML y DL. También se mencionan otros tipos de métodos de detección, como los basados en firmas y los híbridos.

Finalmente, se explica que el artículo está organizado en secciones que abordan similitudes y diferencias entre ML y DL, conjuntos de datos de ciberseguridad utilizados en ML y DL, descripciones de métodos y trabajos relacionados en ciberseguridad, estado actual de la investigación y direcciones futuras, y conclusiones.

En resumen, el artículo se centra en la importancia de la ciberseguridad en un mundo cada vez más conectado, describe diferentes enfoques de detección de intrusiones y proporciona una revisión de la literatura sobre métodos de ML y DL en ciberseguridad.


El texto discute diversas aproximaciones y métodos para la detección de intrusiones en redes utilizando diferentes técnicas de aprendizaje automático. Se centra en el uso de conjuntos de datos como los Conjuntos de Datos de Detección de Intrusiones DARPA, el Conjunto de Datos KDD Cup 99, el Conjunto de Datos NSL-KDD y el Conjunto de Datos ADFA para entrenar y probar modelos de detección de intrusiones. Se exploran los siguientes algoritmos de aprendizaje automático:

Máquina de Vectores de Soporte (SVM): Se utiliza SVM para clasificar diferentes tipos de ataques de red, y su rendimiento se evalúa en términos de precisión y tasa de falsas alarmas. Se han realizado varios estudios para optimizar SVM en la detección de intrusiones, con resultados que muestran tasas de detección prometedoras pero variaciones en las falsas alarmas.

K-Vecinos Más Cercanos (kNN): Se emplea kNN para clasificar el tráfico de red en función de su similitud con patrones de ataque conocidos. Los estudios han demostrado que kNN puede ser eficaz en la detección de intrusiones, especialmente cuando se combina con otras técnicas. Ayuda a reducir las falsas alarmas y mejorar las tasas de detección.

Árbol de Decisión: Se utilizan árboles de decisión para la detección de intrusiones, y se exploran diferentes enfoques para mejorar su rendimiento. Se aplican técnicas de selección de características, poda de árboles y optimización para mejorar la precisión y reducir las falsas alarmas. Los árboles de decisión pueden proporcionar alta precisión y son particularmente efectivos para detectar ataques conocidos.

En resumen, el texto destaca la importancia de elegir el algoritmo de aprendizaje automático adecuado y el conjunto de datos para la detección de intrusiones. Diferentes algoritmos tienen sus fortalezas y debilidades, y su rendimiento puede variar según los tipos específicos de ataques y conjuntos de datos utilizados. Los investigadores trabajan continuamente para mejorar la precisión y reducir las falsas alarmas en los sistemas de detección de intrusiones en redes.


 El texto proporcionado es un fragmento de un artículo de investigación que discute la aplicación de métodos de Aprendizaje Automático (ML) y Aprendizaje Profundo (DL) en el campo de la seguridad de redes, centrándose específicamente en la detección de intrusiones. Ofrece una visión general de diferentes técnicas de ML y DL, conjuntos de datos y tendencias en la investigación de detección de intrusiones.

El texto menciona varios métodos de ML y DL, como las Redes de Creencias Profundas (DBN), las Redes Neuronales Recurrentes (RNN) y las Redes Neuronales Convolucionales (CNN). Estos métodos se aplican para detectar y clasificar intrusiones y anomalías en redes. El fragmento también aborda el uso de conjuntos de datos de referencia y los desafíos relacionados con la calidad de los datos, los datos desequilibrados y la necesidad de conjuntos de datos más extensos y equilibrados.

El artículo destaca la tendencia de combinar diferentes algoritmos en modelos híbridos, lo que puede mejorar el rendimiento de la detección. También enfatiza la importancia de mejorar la velocidad de detección de intrusiones y el potencial del aprendizaje en línea para adaptarse a amenazas en constante evolución.

En resumen, este texto ofrece una visión general del estado de la investigación en la detección de intrusiones utilizando métodos de ML y DL, así como algunos de los desafíos y direcciones futuras en este campo. Si tienes alguna pregunta específica o necesitas más información sobre alguna parte de este texto, no dudes en preguntar.


\citep{martinez2019machine} Ingles


\citep{sarker2022machine} Ingles


\citep{stamp2022artificial} : INLES Redes neuronales y ciberseguridad

\citep{haber2017data} : INGLES muchos articulos, filtrar interesnates ciberseguridad

\citep{kim2018network} : INGLES Cubre temas relacionados con la detección de intrusiones y la aplicación de modelos de aprendizaje profundo en este campo, lo que es altamente relevante para la ciberseguridad.

La serie tiene como objetivo desarrollar y difundir una comprensión de innovaciones, paradigmas, técnicas y tecnologías en el contexto de la investigación y estudios relacionados con sistemas y redes de ciberseguridad. Publica revisiones exhaustivas y cohesivas de temas de vanguardia en ciberseguridad, así como técnicas sofisticadas, presentaciones de investigaciones originales y estudios de casos en profundidad en sistemas y redes cibernéticas. La serie también proporciona un único punto de cobertura de temas avanzados y emergentes oportunos, así como un foro para conceptos fundamentales que pueden no haber alcanzado un nivel de madurez para justificar un libro de texto integral. Se abordan problemas de seguridad, privacidad, disponibilidad y confiabilidad para sistemas y redes cibernéticas, y se dan la bienvenida a tecnologías emergentes, como inteligencia artificial, computación en la nube, sistemas ciberfísicos y análisis de grandes datos relacionados con la investigación en ciberseguridad. Se centra principalmente en los siguientes temas de investigación:
Fundamentos y Teorías
• Criptografía para la ciberseguridad
• Teorías de la ciberseguridad
• Seguridad demostrable

Sistemas y Redes Cibernéticas
• Seguridad de sistemas cibernéticos
• Seguridad de redes
• Servicios de seguridad
• Seguridad y privacidad de redes sociales
• Ataques y defensa cibernéticos
• Ciberseguridad basada en datos
• Computación y sistemas de confianza

Aplicaciones y Otros
• Seguridad de hardware y dispositivos
• Seguridad de aplicaciones cibernéticas
• Aspectos humanos y sociales de la ciberseguridad





Este monográfico presenta avances recientes en el Sistema de Detección de Intrusiones (IDS) utilizando modelos de aprendizaje profundo, que han logrado un gran éxito recientemente, especialmente en el campo de la visión por computadora, el procesamiento del lenguaje natural y el procesamiento de imágenes. El monográfico ofrece una visión sistemática y metódica de los últimos desarrollos en aprendizaje profundo y realiza una comparación entre IDS basados en aprendizaje profundo. También ofrece una descripción general completa de las aplicaciones del aprendizaje profundo en IDS, seguida de métodos de aprendizaje de características profundas que incluyen una novedosa extracción y selección de características profundas, y el aprendizaje profundo para el agrupamiento.
Está destinado a estudiantes, investigadores y profesionales interesados en el aprendizaje profundo y la detección de intrusiones, y puede utilizarse como libro de referencia. La comparación exhaustiva de varias aplicaciones de aprendizaje profundo ayuda a los lectores con una comprensión básica del aprendizaje automático e inspira aplicaciones en IDS y otras áreas de ciberseguridad.
El monográfico consta de varios capítulos, donde el Capítulo 1 destaca la importancia de los IDS en las redes de computadoras en la actualidad, proporcionando una encuesta de violaciones de seguridad en redes de computadoras. Se resalta que los modelos de aprendizaje profundo pueden mejorar el rendimiento de los IDS y se explica la motivación para examinar los IDS basados en aprendizaje profundo. El Capítulo 2 define IDS y explica los diferentes tipos de IDS actuales, así como las métricas de rendimiento comunes y conjuntos de datos de referencia públicos disponibles.
El Capítulo 3 realiza un estudio preliminar breve sobre el aprendizaje automático clásico, que abarca enfoques supervisados, no supervisados, semi-supervisados, débilmente supervisados, de refuerzo y adversariales. También se revisan brevemente 22 artículos que utilizan técnicas de aprendizaje automático en sus IDS. El Capítulo 4 se centra en diversos modelos de aprendizaje profundo que incluyen enfoques generativos, discriminatorios y híbridos.
El Capítulo 5 realiza un análisis de varios IDS que aprovechan modelos de aprendizaje profundo, divididos en cuatro clases: generativos, discriminativos, híbridos y aprendizaje profundo por refuerzo.
El Capítulo 6 aborda la importancia de los modelos de aprendizaje profundo como enfoque de aprendizaje de características (FL) en investigaciones de IDS. También se explican dos modelos adicionales: la extracción y selección de características profundas y el aprendizaje profundo para el agrupamiento.
El Capítulo 7 concluye este monográfico proporcionando una visión general de los desafíos y las futuras direcciones de investigación en las aplicaciones de aprendizaje profundo para IDS.
En el Apéndice, se discuten varios artículos sobre la detección de malware en una red utilizando modelos de aprendizaje profundo. La detección de malware también es un aspecto importante.


\citep{xu2023machine} : INGLES Mucho texto 2 conferencia de no se que

\citep{alfaries2019advances} : INLES Ciberseguridad pero mucha basura. Filtrar.
\begin{enumerate}
\item Comparison of Supervised and Unsupervised Fraud Detection 
\item Cybersecurity: Design and Implementation of an Intrusion Detection
and Prevention System.
\end{enumerate}


\citep{kalash2018malware} : Articulo en ingles del review. Es el caso de deteccionde malware usando CNN con el dataset de Microsoft. Te visualiza y explica como pasar de los datos a imagenes. Además te dice como sería el modelo de CNN con las capas y dimensiones. Por ultimo te dice la informacion necesaria como el indice de aprendizaje y las epochs necesarias para obtener el 98,7 \% de acurrancy

\end{comment}













  
\newpage

\medskip
\nocite{*}
\bibliographystyle{plain}
\bibliography{biblio}
\clearpage

\newpage

\printglossary

\newpage

\appendix

\chapter{Anexo A} \label{anexoa}

Para determinar estos pesos, deben calcularse usando la siguiente fórmula:

\[
W_j = \sqrt{\frac{s}{c \cdot S_j}}
\]

Donde $W_j$ representa el peso de la clase $j$, $s$ es el número total de muestras, $c$ es el número total de clases y $S_j$ es el número de muestras de la clase $j$. Estos pesos se emplean durante el cálculo de la función de pérdida. Una vez que se ha calculado la pérdida para cada clase, esta se multiplica por el peso correspondiente de la clase. Este procedimiento permite ``balancear'' la importancia relativa de cada clase durante el entrenamiento de la red.

\chapter{Anexo B} \label{anexob}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
Clase & Precisión & TPR (Sensibilidad) & FPR & F1 Score \\ \hline
1 & 0.94 & 0.97 & 0.06 & 0.96 \\ \hline
2 & 0.92 & 0.97 & 0.07 & 0.94 \\ \hline
3 & 0.97 & 0.99 & 0.03 & 0.98 \\ \hline
4 & 0.91 & 1.00 & 0.09 & 0.95 \\ \hline
5 & 0.49 & 0.33 & 0.06 & 0.39 \\ \hline
6 & 0.94 & 0.90 & 0.03 & 0.92 \\ \hline
7 & 0.95 & 0.95 & 0.05 & 0.95 \\ \hline
8 & 0.88 & 0.90 & 0.12 & 0.89 \\ \hline
9 & 0.94 & 0.93 & 0.06 & 0.94 \\ \hline
\end{tabular}
\caption{Métricas de rendimiento por clase}
\label{tab:metrics}
\end{table}

\end{document}


