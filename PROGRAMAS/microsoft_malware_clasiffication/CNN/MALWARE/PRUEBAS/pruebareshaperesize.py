
"""
Nombre del codigo: Modelo de CNN de reconocimiento de malware.
Base de datos: Microsoft Malware Dataset
Alumno: Jim√©nez Poyatos, Pablo

Script solo con el modelo. Nada de representaci√≥n de datos ni nada. Adem√°s el codigo apilado en funciones.

Para crear el modelo, he necesitado instalarme diferentes bibliotecas como numpy, tensorflow, keras, etc.

Adem√°s, he tenido que descargarme las imagenes de entrenamiento en diferentes carpetas (cada clase en una carpeta) 
y guardarlas en la misma carpeta donde estaba este script.

"""
from math import floor, sqrt
import numpy as np
import matplotlib.pyplot as plt
import csv
import os                                              # Importamos el m√≥dulo os para interactuar con el sistema operativo
import cv2
import multiprocessing as mp                    
from PIL import Image                                  # Importamos la clase Image del m√≥dulo PIL para trabajar con im√°genes
import random
import pickle


def reparte(numero: int, nr_partes: int) -> list[int]:
    """Divide `numero` en `nr_partes` partes enteras más o menos iguales.
    Por ejemplo, reparte(10, 3) devuelve la lista [4, 3, 3]."""
    cociente, resto = divmod(numero, nr_partes)
    return [cociente + 1] * resto + [cociente] * (nr_partes - resto)

def generar_listas(lista, totales):
    resultado = []
    inicio = 0

    for longitud in lista:
        nueva_lista = totales[inicio:longitud+1]
        resultado.append(nueva_lista)
        totales = totales[longitud+1:]

    return resultado


def concat(xss):
    xs = []
    for i in xss:
        xs += i
    return xs

def first(par):
    return par[0]

def second(par):
    return par[1]

def random_crop(image_array, crop_size=(224, 224)):
    # Convertir el array NumPy a una imagen PIL
    image = Image.fromarray(image_array)

    # Obtener las dimensiones originales de la imagen
    original_width, original_height = image.size

    # Calcular las coordenadas del recorte aleatorio
    left = np.random.randint(0, original_width - crop_size[0] + 1)
    top = np.random.randint(0, original_height - crop_size[1] + 1)
    right = left + crop_size[0]
    bottom = top + crop_size[1]

    # Aplicar el recorte aleatorio a la imagen
    cropped_image = image.crop((left, top, right, bottom))

    # Convertir la imagen recortada de nuevo a un array NumPy
    cropped_array = np.array(cropped_image)

    return cropped_array

def bytes_to_image(byte_str, width, height):
    byte_list = [int(byte, 16) for line in byte_str.split('\n') for byte in line.split()[1:]]
    image_array = np.array(byte_list)
    lon = len(image_array)
    lado = floor(sqrt(lon))
    if lado == 0:
        return np.empty((0,0))
    
    lado2 = lon // lado
    image_array = image_array[:lado*lado2]
    image_matrix2 = image_array.reshape((lado, lado2))
    
    image_matrix2 = image_matrix2.astype(np.uint8)
    grayscale_image2 = cv2.resize(image_matrix2, (width, height))

    # Expande las dimensiones para indicar que es una imagen en escala de grises
    result_image2 = np.stack([grayscale_image2] * 3, axis=-1)
    
    
    return result_image2


def visualize_image(image_matrix):
    plt.imshow(image_matrix, cmap='gray')
    plt.axis('off')
    plt.show()
    

def file_to_image(name):

    # Read lines from the file
    #ruta = os.path.join('train2')
    ruta_archiv = os.path.join(name)
    lines = open(ruta_archiv, "r").readlines()

    # Format lines into a string
    malware_bytes = """ """ + "\n".join(lines)

    malware_bytes = "\n".join(line for line in malware_bytes.split("\n") if "?" not in line)

    # Set the desired width and height for the image
    image_width = 224
    image_height = 224

    # Convert the .bytes file snippet to a grayscale image
    malware_image = bytes_to_image(malware_bytes, image_width, image_height)

    # Visualize the image
    #visualize_image(malware_image)
    return malware_image

def leer_csv(name):

    # Diccionario para almacenar id y label
    diccionario_id_label = {}

    # Leer el archivo CSV
    with open(name, newline='') as csvfile:
        # Crear un objeto lector CSV
        lector = csv.DictReader(csvfile)

        # Iterar sobre las filas del archivo CSV
        for fila in lector:
            # Obtener valores de las columnas "Id" y "Class"
            id_valor = fila['Id']  
            label_valor = fila['Class']

            # Almacenar en el diccionario
            diccionario_id_label[id_valor] = label_valor
    return diccionario_id_label


def verificar_extension(archivo):
    # Obtener la extensión del archivo
    _, extension = os.path.splitext(archivo)

    # Comparar la extensión con '.bytes' o '.asm'
    if extension.lower() == '.bytes':
        return True
    else:
        return False

# Definimos una funci√≥n para cargar y procesar datos
def load_and_preprocess_data(ruta, trainLabel, images):

    data = []                                         # Lista para almacenar datos de im√°genes
    labels = []                                       # Lista para almacenar etiquetas de im√°genes                         
    
    for i in images:  
        imagen = file_to_image(i)
        if imagen.size == 0:
            print(i)
            pass
        else:
            data.append(imagen)
            Id = os.path.splitext(i)[0]
            label = trainLabel[Id]
            labels.append(label)

    return data, labels
    


def load_and_preprocess_data_paralelo(nr_procesos):
    p = mp.Pool(nr_procesos)
    
    ruta = os.path.join('train2')
    images_tot = os.listdir(ruta)
    images_tot = list(filter(verificar_extension, images_tot))
    trainLabel = leer_csv('trainLabels.csv')
    
    reparto_doc = reparte(len(images_tot), nr_procesos)
    archivos = generar_listas(reparto_doc, images_tot)
    args_list = [(ruta,trainLabel,k) for k in archivos]
    resultados = p.starmap(load_and_preprocess_data, args_list)
    
    data = concat(list(map(first,resultados)))
    label = concat(list(map(second,resultados)))
    label = np.array(label)
    data = np.array(data)
    
    return data, label



        
#predecir('traffic_classifier.keras','Hf2WOklmDrv5G6cEba7h.bytes')
def generate_and_process_images():
    # Obtener la lista de archivos en el directorio
    file_list = os.listdir()

    # Filtrar los archivos que terminan en ".bytes"
    bytes_files = [file for file in file_list if file.endswith(".bytes")]

    # Aplicar la función file_to_image a cada archivo
    for file in bytes_files:
        file_to_image(file) 
#generate_and_process_images()



def guardar_imagen(imagen, nombre_archivo):
    # Aquí debes ajustar la ruta y el nombre del directorio según tus necesidades
    directorio_destino = "images_python"
    ruta_completa = os.path.join(directorio_destino, nombre_archivo)
    imagen.save(ruta_completa)

def procesar_archivos():
    file_list = os.listdir()

    # Filtrar los archivos que terminan en ".bytes"
    lista_archivos = [file for file in file_list if file.endswith(".bytes")]
    diccionario = leer_csv('trainLabels.csv')
    lista_archivos = ['da3XhOZzQEbKVtLgMYWv.bytes']
    for contador, archivo in enumerate(lista_archivos, start=1):
        if archivo[:-6] in diccionario:
            imagen_resultante = file_to_image(archivo)
            nombre_guardado = f"{diccionario[archivo[:-6]]}+{contador}.png"
            imagen_array = np.squeeze(imagen_resultante)
            imagen_pil = Image.fromarray(imagen_array)
            # Guardar la imagen usando el método 'save' de PIL
            imagen_pil.save(nombre_guardado)
            print(imagen_resultante.shape[2], flush=True)
            
def ver_imagenes_load(data,label):
    num_al = []
    i = 0
    while i < 100:
        num = random.randint(0,len(label))
        if num not in num_al:
            num_al.append(num)
            i += 1
    contador = 0
    for i in range(len(num_al)):
        image = data[num_al[i]]           
        nombre_guardado = f"{label[num_al[i]]}+{contador}.png"
        imagen_array = np.squeeze(image)
        imagen_pil = Image.fromarray(imagen_array)
        # Guardar la imagen usando el método 'save' de PIL
        imagen_pil.save(nombre_guardado)
        print(image.shape[2], flush=True)
        contador +=1
#procesar_archivos()

#procesar_archivos()
with open('resultados.pkl', 'rb') as f:
        data,labels = pickle.load(f)
labels = labels.astype(np.int64)
ver_imagenes_load(data, labels)
