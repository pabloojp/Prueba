# -*- coding: utf-8 -*-
"""
Created on Tue Feb 13 20:21:39 2024

@author: pjime
"""

import numpy as np
import csv
import math
import tensorflow as tf                                # Importamos TensorFlow, una biblioteca para aprendizaje autom√°tico                                            # Importamos el m√≥dulo os para interactuar con el sistema operativo
from sklearn.model_selection import train_test_split   # Importamos train_test_split para dividir los datos en conjuntos de entrenamiento y prueba
from keras.utils import to_categorical                 # Importamos to_categorical para codificar las etiquetas en formato one-hot
from keras.models import Sequential                   # Importamos Sequential, un modelo lineal para apilar capas de red neuronal
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout   # Importamos capas espec√≠ficas para construir una red neuronal convolucional
import pickle
from tf.keras.optimizers import SGD
from tensorflow.keras.callbacks import LearningRateScheduler
import time



class TimeHistory(tf.keras.callbacks.Callback):
    
        def on_train_begin(self, logs={}):
            self.times = []

        def on_epoch_begin(self, epoch, logs={}):
            self.epoch_time_start = time.time()

        def on_epoch_end(self, epoch, logs={}):
            self.times.append(time.time() - self.epoch_time_start)
            


def split_and_encode_data(data, labels, test_size=0.1, random_state=10):
    
    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=test_size, random_state=random_state) 
    
    y_train -= 1                       
    y_test -= 1
    
    y_test = to_categorical(y_test, 9)  
    y_train = to_categorical(y_train, 9)  
    
    return X_train, X_test, y_train, y_test



def build_model(input_shape, dropout = 0, reluSoftmax = False, layer1000 = False ):
    
    model = Sequential()
    
    model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding="same", activation="relu"))
    model.add(Conv2D(filters=64,kernel_size=(3,3),padding="same", activation="relu"))
    
    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))

    model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
    
    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
    
    model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
    
    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
    
    model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
    
    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
    
    model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
    
    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
    
    model.add(Flatten())
    model.add(Dense(units=4096,activation="relu"))
    
    if dropout != 0:
        model.add(Dropout(dropout))
        
    model.add(Dense(units=4096,activation="relu"))
    
    if dropout != 0:
        model.add(Dropout(dropout))
        
    if reluSoftmax:
        model.add(Dense(units=9, activation='relu'))
        
        if dropout != 0:
            model.add(Dropout(dropout))
    
    if layer1000:
        model.add(Dense(units=1000, activation='relu'))
        
    model.add(Dense(units=9, activation='softmax'))

    model.summary()
    
    return model


def step_decay(epoch, drop):
    
   initial_lrate = 0.001
   drop = 0.1
   epochs_drop = drop
   
   lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))
   
   return lrate



def historial(history, time_callback, nombre):
    
    train_loss = []
    train_acc = []
    val_loss = []
    val_acc = []
    times = []

    train_loss = history.history['loss']
    train_acc = history.history['accuracy']
    val_loss = history.history['val_loss']
    val_acc = history.history['val_accuracy']
    times = time_callback.times


    with open(nombre, 'w', newline='') as csvfile:
        
        fieldnames = ['epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'time']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        
        for i in range(len(train_loss)):
            writer.writerow({'epoch': i+1, 'train_loss': train_loss[i], 'train_acc': train_acc[i], 'val_loss': val_loss[i], 'val_acc': val_acc[i], 'time': times[i]})

    
    
def train_model(model, file_name, X_train, y_train, X_test, y_test, batch_size=8, epochs=25):
    
    initial_learning_rate = 0.001
    momentum = 0.9
    lr_schedule = LearningRateScheduler(step_decay)
    sgd_optimizer = SGD(learning_rate=initial_learning_rate, momentum=momentum, weight_decay=0.0005)
    model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    
    time_callback = TimeHistory()
    
    with tf.device('/GPU:0'):
        history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), callbacks=[lr_schedule, time_callback], shuffle=True)
    
    historial(history, time_callback, file_name)

    model.save(file_name + '.keras')

    return history


if __name__ == "__main__":
    
    nombre = ''
    
    with open('resultados.pkl', 'rb') as f:
        data,labels = pickle.load(f)
        
    labels = labels.astype(np.int64)
    
    X_train, X_test, y_train, y_test = split_and_encode_data(data, labels)
       
    model = build_model(X_train.shape[1:], dropout = 0.5, reluSoftmax = False, layer1000 = False) 
    
    train_model(model, nombre, X_train, y_train, X_test, y_test, 16, 25)













