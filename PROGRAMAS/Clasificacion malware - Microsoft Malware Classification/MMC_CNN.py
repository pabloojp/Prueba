"""
Nombre del codigo: Modelo de CNN de clasificación de malware.
Base de datos: Microsoft Malware Dataset
Alumno: Jim√©nez Poyatos, Pablo

"""

import numpy as np
import math
import pickle
import tensorflow as tf

from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout
from keras.callbacks import EarlyStopping, CSVLogger
from tensorflow.keras.callbacks import LearningRateScheduler
from aux import grafico_datos, split_and_encode_data, TimeHistory
from confusionMMC_CNN import confusion_matrix_pablo


def build_model(dropout: float = 0.0) -> Sequential:
    """
    Construye y retorna un modelo CNN para la clasificación de malware.

    Args:
        dropout (float): La tasa de dropout a aplicar en las capas densas. Por defecto es 0.0.

    Returns:
        model (Sequential): El modelo CNN compilado.
    """
    model = Sequential()

    # Bloque 1
    model.add(Conv2D(input_shape=(224, 224, 3), filters=64, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))

    # Bloque 2
    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))

    # Bloque 3
    model.add(Conv2D(filters=256, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(Conv2D(filters=256, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(Conv2D(filters=256, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))

    # Bloque 4
    model.add(Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))

    # Bloque 5
    model.add(Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(Conv2D(filters=512, kernel_size=(3, 3), padding="same", activation="relu"))
    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))

    # Capas densas
    model.add(Flatten())
    for i in range(2):
        model.add(Dense(units=4096, activation="relu"))
        if dropout != 0:
            model.add(Dropout(dropout))

    model.add(Dense(units=9, activation='softmax'))

    model.summary()

    return model


def step_decay(epoch: int) -> float:
    """
    Calcula la tasa de aprendizaje en función del número de épocas.

    Args:
        epoch (int): El número de épocas.

    Returns:
        lrate (float): La tasa de aprendizaje ajustada.
    """
    initial_lrate = 0.001
    drop = 0.1
    epochs_drop = 20.0
    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))
    return lrate


def train_model(model: Sequential, file_name: str, X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray,
                y_val: np.ndarray, csv: CSVLogger, batch_size: int = 8, epochs: int = 25) -> None:
    """
    Entrena el modelo CNN con los datos proporcionados.

    Args:
        model (Sequential): El modelo CNN a entrenar.
        file_name (str): El nombre del archivo para guardar el modelo.
        X_train (np.ndarray): Los datos de entrenamiento.
        y_train (np.ndarray): Las etiquetas de entrenamiento.
        X_val (np.ndarray): Los datos de validación.
        y_val (np.ndarray): Las etiquetas de validación.
        csv (CSVLogger): El logger de CSV para guardar el historial de entrenamiento.
        batch_size (int): El tamaño del lote para el entrenamiento. Por defecto es 8.
        epochs (int): El número de épocas para el entrenamiento. Por defecto es 25.

    Returns:
        None
    """
    # Inicialización de parámetros
    initial_learning_rate = 0.001
    momentum = 0.9

    # Callbacks
    lr_schedule = LearningRateScheduler(step_decay)
    early_stopping = EarlyStopping(monitor='val_accuracy', patience=4,
                                   restore_best_weights=True, start_from_epoch=20)

    # Compilación y entrenamiento
    sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=initial_learning_rate, momentum=momentum, weight_decay=0.0005)
    model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),
              callbacks=[lr_schedule, early_stopping, csv], shuffle=True)

    model.save(file_name + '.keras')


def load_data(data_name: str) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    Carga los datos de entrenamiento y prueba desde un archivo pickle.

    Args:
        data_name (str): El nombre del archivo pickle que contiene los datos.

    Returns:
        tuple: Los datos de entrenamiento, validación y prueba junto con sus etiquetas.
    """
    with open(data_name, 'rb') as f:
        data, labels = pickle.load(f)
    labels = labels.astype(np.int64)

    X_train, X_modelo, y_train, y_modelo = split_and_encode_data(data, labels, test_size=0.25, random_state=0)
    X_val, X_test, y_val, y_test = train_test_split(X_modelo, y_modelo, test_size=0.6, random_state=1)

    return X_train, y_train, X_val, y_val, X_test, y_test
    
if __name__ == "__main__":
    # Hiperparámetros modelo
    names = "malware_classifier"
    nombres = "malware_classifier"
    dropout = 0.5
    lr_drop = 20
    batch_size = 8
    epochs = 25

    # Cargar datos
    X_train, y_train, X_val, y_val, X_test, y_test = load_data('eliminarL.pkl')
    grafico_datos(y_train, y_test, y_val)

    # Entrenar y compilar el modelo
    csv_logger_clas = CSVLogger('CNN_training.csv', append=False)
    model = build_model(dropout) #
    train_model(model, nombres, X_train, y_train, X_val, y_val, csv_logger_clas, batch_size, epochs)

    # Evaluar el modelo
    confusion_matrix_pablo('malware_classifier.keras', X_test, y_test, 'confusionMatrixCNN')

