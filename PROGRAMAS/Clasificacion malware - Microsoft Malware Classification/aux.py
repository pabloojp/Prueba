
"""
Nombre del codigo: Funciones auxiliares utilizadas en el estudio.
Base de datos: Microsoft Malware Dataset
Alumno: Jim√©nez Poyatos, Pablo

"""

import csv
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import tensorflow as tf

from sklearn.model_selection import train_test_split
from keras.utils import to_categorical


def grafico_datos(y_train: np.ndarray, y_test: np.ndarray, y_val: np.ndarray) -> None:
    """
    Genera gráficos de distribución de datos de entrenamiento, prueba y validación.

    Args:
        y_train (np.ndarray): Etiquetas de los datos de entrenamiento.
        y_test (np.ndarray): Etiquetas de los datos de prueba.
        y_val (np.ndarray): Etiquetas de los datos de validación.
    """
    df = pd.read_csv("trainLabels.csv", index_col="Id")
    malware_typ = ["Ramnit", "Lollipop", "Kelihos_ver3", "Vundo", "Simda", "Tracur", "Kelihos_ver1", "Obfuscator.ACY",
                   "Gatak"]
    malware_clasif = dict(zip(range(1, 10), malware_typ))
    distribucion = []
    for i in range(1, 10):
        contador = df.apply(lambda x: x['Class'] == i, axis=1).sum()
        distribucion.append([malware_clasif[i], contador])
    init = pd.DataFrame(distribucion)
    init.index = range(1, 10)

    bucle = [(y_train, "train"), (y_test, "test"), (y_val, "val")]
    for i in bucle:
        distribu = pd.DataFrame([np.where(r == 1)[0][0] for r in i[0]])
        distrib = []
        for j in range(9):
            contador = distribu.apply(lambda x: x[0] == j, axis=1).sum()
            distrib.append(contador)
        init[i[1]] = distrib
    init.columns = ["Tipo malware", "Total", "Train", "Test", "Validation"]
    init.loc[1, 'Total'] = 1533

    # Barras:
    plt.figure()
    init.plot(title='Distribución del training dataset (Microsoft BIG 2015)',
              kind='bar', rot=0, legend=True)
    plt.tight_layout()
    plt.savefig("barras4MMC.png")
    plt.show()

    # Circular
    malware_typ2 = ["1.Ramnit", "2.Lollipop", "3.Kelihos_ver3", "4.Vundo",
                    "5.Simda", "6.Tracur", "7.Kelihos_ver1", "8.Obfuscator.ACY",
                    "9.Gatak"]
    plt.figure()
    label = range(1, 10)
    sizes = init["Total"]
    plt.pie(sizes, labels=label, startangle=260, autopct='%1.1f%%')
    plt.legend(labels=malware_typ2, loc='upper right')
    plt.axis('equal')
    plt.tight_layout()
    plt.savefig("circularMMC.png")
    plt.show()


def split_and_encode_data(data: np.ndarray, labels: np.ndarray, test_size: float = 0.1,
                          random_state: int = 10) -> tuple:
    """
    Divide los datos en conjuntos de entrenamiento y prueba, y codifica las etiquetas en formato one-hot.

    Args:
        data (np.ndarray): Datos de entrada.
        labels (np.ndarray): Etiquetas de los datos.
        test_size (float): Proporción del conjunto de prueba. Por defecto es 0.1.
        random_state (int): Semilla para la aleatoriedad. Por defecto es 10.

    Returns:
        tuple: Conjuntos de datos y etiquetas para entrenamiento y prueba.
    """
    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=test_size, random_state=random_state)
    y_train -= 1  # Las clases van de 1 a 9, pero la codificación one-hot es de 0 a n-1, luego tenemos que reetiquetar cada imagen
    y_test -= 1
    y_test = to_categorical(y_test, 9)
    y_train = to_categorical(y_train, 9)
    return X_train, X_test, y_train, y_test


def guardar_informacion(history: tf.keras.callbacks.History, file_name: str, time_callback: TimeHistory) -> None:
    """
    Guarda el historial de entrenamiento en un archivo CSV.

    Args:
        history (tf.keras.callbacks.History): Historial de entrenamiento.
        file_name (str): Nombre del archivo CSV.
        time_callback (TimeHistory): Callback para registrar los tiempos por época.
    """
    # Record history
    train_loss = history.history['loss']
    train_acc = history.history['accuracy']
    val_loss = history.history['val_loss']
    val_acc = history.history['val_accuracy']
    times = time_callback.times

    with open(file_name, 'w', newline='') as csvfile:
        fieldnames = ['epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'time']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for i in range(len(train_loss)):
            writer.writerow({'epoch': i + 1, 'train_loss': train_loss[i],
                             'train_acc': train_acc[i], 'val_loss': val_loss[i],
                             'val_acc': val_acc[i], 'time': times[i]})