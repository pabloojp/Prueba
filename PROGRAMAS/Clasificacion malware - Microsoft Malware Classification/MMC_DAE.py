"""
Nombre del codigo: Modelo de un Deep Autoencoder para clasificación de malware.
Base de datos: Microsoft Malware Dataset
Alumno: Jiménez Poyatos, Pablo
"""

import tensorflow as tf
import numpy as np
import pickle

from aux import split_and_encode_data
from MMC_CNN import step_decay
from tensorflow.keras import layers, models, Model
from keras.models import load_model
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import CSVLogger, LearningRateScheduler, EarlyStopping

# Definir la arquitectura del autoencoder convolucional
def build_deep_autoencoder(input_shape: int) -> models.Model:
    """
    Construye un autoencoder profundo.

    Args:
        input_shape (int): La forma de entrada para la capa de entrada del autoencoder.

    Returns:
        models.Model: Un modelo de autoencoder compilado.

    Input:
        - input_shape: Un entero que representa la dimensión de la entrada.

    Output:
        - Un modelo de autoencoder de Keras.
    """
    # Encoder
    input_layer = layers.Input(shape=(input_shape,))

    # Hidden layers for the encoder
    encoded = layers.Dense(12800, activation='relu')(input_layer)
    encoded = layers.Dropout(0.4)(encoded)
    encoded = layers.Dense(6400, activation='relu')(encoded)
    encoded = layers.Dropout(0.4)(encoded)
    encoded = layers.Dense(4096, activation='relu')(encoded)  # Bottleneck layer
    encoded = layers.Dropout(0.4)(encoded)

    # Decoder
    decoded = layers.Dense(6400, activation='relu')(encoded)
    decoded = layers.Dropout(0.4)(decoded)
    decoded = layers.Dense(12800, activation='relu')(decoded)
    decoded = layers.Dense(input_shape, activation='sigmoid')(decoded)  # Output layer

    autoencoder = models.Model(input_layer, decoded)

    autoencoder.summary()

    return autoencoder

def build_classification_model(encoder: models.Model, input_shape: int, num_classes: int) -> models.Model:
    """
    Construye un modelo de clasificación utilizando un encoder preentrenado.

    Args:
        encoder (models.Model): Un modelo preentrenado que actúa como el encoder.
        input_shape (int): La forma de entrada para el modelo de clasificación.
        num_classes (int): El número de clases para la salida de clasificación.

    Returns:
        models.Model: Un modelo de clasificación compilado.

    Input:
        - encoder: Un modelo de Keras que actúa como el encoder.
        - input_shape: Un entero que representa la dimensión de la entrada.
        - num_classes: Un entero que representa el número de clases de salida.

    Output:
        - Un modelo de clasificación de Keras.
    """
    # Congelar las capas del encoder
    for layer in encoder.layers:
        print(layer)
        layer.trainable = False

    # Añadir capas de clasificación
    classification_input = layers.Input(shape=(input_shape,))
    x = encoder(classification_input)
    x = layers.Dense(4096, activation='relu')(x)
    x = layers.Dropout(0.5)(x)
    x = layers.Dense(4096, activation='relu')(x)
    x = layers.Dropout(0.5)(x)
    classification_output = layers.Dense(num_classes, activation='softmax')(x)  # Suponiendo num_classes clases

    classification_model = models.Model(classification_input, classification_output)
    classification_model.summary()

    return classification_model


if __name__ == "__main__":
    # Hiperparámetros iniciales
    file_name = "MMC_autoencoder"
    input_shape = 50176
    epochsAE = 25
    batch_sizeAE = 8
    epochsC = 50
    batch_sizeC = 8
    num_classes = 9
    csv_logger = CSVLogger('autoencoder_training_DAE.csv', append=False)
    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

    # Procesar datos
    with open('eliminarL.pkl', 'rb') as f:
        data, labels = pickle.load(f)
    labels = labels.astype(np.int64)

    with open('eliminarL_test.pkl', 'rb') as f:
        data2 = pickle.load(f)

    X_trainC, X_modeloC, y_trainC, y_modeloC = split_and_encode_data(data, labels, test_size=0.25, random_state=0)
    X_valC, X_testC, y_valC, y_testC = train_test_split(X_modeloC, y_modeloC, test_size=0.6, random_state=1)

    X_train, X_val = train_test_split(data2, test_size=0.2, random_state=2)

    X_train = np.concatenate([X_trainC, X_train], axis=0)
    X_val = np.concatenate([X_val, X_valC], axis=0)

    X_train = np.array([x.reshape(50176, -1) for x in ((X_train.astype('float32') / 255.0)[:,:,:,0])])
    X_val = np.array([x.reshape(50176, -1) for x in ((X_val.astype('float32') / 255.0)[:,:,:,0])])
    X_trainC = np.array([x.reshape(50176, -1) for x in ((X_trainC.astype('float32') / 255.0)[:,:,:,0])])
    X_valC = np.array([x.reshape(50176, -1) for x in ((X_valC.astype('float32') / 255.0)[:,:,:,0])])
    X_testC = np.array([x.reshape(50176, -1) for x in ((X_testC.astype('float32') / 255.0)[:,:,:,0])])

    # Cargar y entrenar modelo autoencoder
    autoencoder = build_deep_autoencoder(input_shape)
    autoencoder.compile(optimizer='adam', loss='mse')
    autoencoder.fit(X_train, X_train, epochs=epochsAE, batch_size=batch_sizeAE, validation_data=(X_val, X_val),
                    callbacks=[csv_logger, early_stopping], shuffle=True)
    autoencoder.save(file_name + '_dae_20.keras')

    # Cargar y entrenar modelo clasificación a partir de la representación comprimida de los datos
    initial_learning_rate = 0.001
    momentum = 0.9
    lr_schedule = LearningRateScheduler(step_decay)
    early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)
    csv_logger_clas = CSVLogger('autoencoder_training_DAE_C_SGD_CE', append=False)

    autoencoder = load_model('MMC_autoencoder_dae_20.keras')
    encoder = Model(inputs=autoencoder.input, outputs=autoencoder.layers[5].output)
    classification_model = build_classification_model(encoder, input_shape, num_classes)

    sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=initial_learning_rate, momentum=momentum, weight_decay=0.0005)
    classification_model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    history = classification_model.fit(X_trainC, y_trainC, batch_size=batch_sizeC, epochs=epochsC, validation_data=(X_valC, y_valC),
                                       callbacks=[early_stopping, csv_logger_clas], shuffle=True)

    classification_model.save(file_name + '.keras')
